 ğŸŒ SafeWeb â€“ AI-Powered Emotional Safety for Women Online
Empowering women to reclaim their digital space.
SafeWeb is a powerful Chrome extension designed to detect and blur toxic content in real-time, offer supportive responses, and notify usersâ€”or guardians in the case of minorsâ€”about emotionally harmful online interactions. Weâ€™re starting with Instagram, and expanding to other platforms across the web.

ğŸ’¡ Why SafeWeb?
Online spaces are becoming increasingly hostile, especially for women and children. With over 70% of women reporting online harassment, and social platforms often falling short in offering proactive solutions, SafeWeb fills the gap by acting as a real-time digital allyâ€”providing emotional safety, privacy control, and responsible reporting.

ğŸš€ Features
ğŸ” AI-Based Toxicity Detection
Identifies harmful, offensive, or abusive language in real-time.

ğŸ›¡ï¸ Custom Safe Zones
Users can define which sections or accounts they want filtered for peace of mind.

ğŸ¤– Smart Reply Assistant
Suggests emotionally intelligent, non-confrontational replies to toxic messages.

ğŸ“¸ Auto Screenshot & Reporting
Automatically captures and stores harmful interactions for user review or reporting.

ğŸ‘¨â€ğŸ‘©â€ğŸ‘§ Parental Notification System
For minors, alerts are sent to guardians for any severe or recurring toxicity incidents.

ğŸ›  Tech Stack & Architecture
SafeWeb combines traditional web technologies, cutting-edge AI/ML models, and decentralized technologies to deliver emotional safety at scale. Here's a breakdown of our complete stack and solution pipeline:

âš™ï¸ Tech Stack
ğŸŒ Frontend
Chrome Extension using JavaScript, HTML, CSS

Web3 Frontend: Ethers.js

Mobile Support (Future): Flutter, React Native

ğŸ§  AI/ML & NLP
Toxicity Detection: Detoxify, Google Perspective API

OCR & Text Extraction: Custom OCR pipeline

ML Model Serving: TensorFlow, Firebase ML

ğŸ§± Backend
Server & APIs: Node.js, Express.js

Database: MongoDB

Authentication & Notifications: Firebase Auth, Cloud Functions, Firebase Cloud Messaging

ğŸ•¸ï¸ Web3 Integration
Blockchain: Ethereum / Polygon

Smart Contracts: Solidity

Decentralized Moderation: DAO-based flag review system

ğŸ§© Solution Architecture
1. User Interaction & Input Stage
Users interact via extension or web interface

Upload screenshots or link accounts

Choose how to handle toxic content (Blur, Remove, Notify)

2. Text Extraction & Toxicity Detection
OCR tools extract text from screenshots

Detoxify model + keyword detection + AI context check to assess explicit and implicit toxicity

3. Content Processing & Decision Making
Based on user settings:

Blur overlays toxic content

Remove deletes it

Notify sends real-time alerts to user or guardian

Real-time detection for incoming messages

4. Blocking & Preventive Measures
Auto-blocks repeat offenders

Adds them to a â€œDetected Harassersâ€ list

Users can manually manage blocked accounts

Future upgrades include predictive sentiment analysis

5. Reporting & Community Involvement
Users can flag content to a Decentralized Moderation DAO

Community votes + AI confidence scores decide outcomes

Ensures fairness and transparency

6. Future Enhancements
Multilingual toxicity detection

Mobile app rollout

Sentiment analysis for deeper insight

Expanded platform compatibility beyond Instagram




